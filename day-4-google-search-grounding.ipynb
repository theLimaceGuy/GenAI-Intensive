{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-4-google-search-grounding.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2024 Google LLC.","metadata":{"id":"kokPyXQaY3xI"}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"cellView":"form","id":"StB_cTIkY1ZG","execution":{"iopub.status.busy":"2024-11-14T03:07:13.107488Z","iopub.execute_input":"2024-11-14T03:07:13.107931Z","iopub.status.idle":"2024-11-14T03:07:13.131652Z","shell.execute_reply.started":"2024-11-14T03:07:13.107883Z","shell.execute_reply":"2024-11-14T03:07:13.130149Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Day 4 - Google Search grounding with the Gemini API\n\nWelcome back to the Kaggle 5-day Generative AI course!\n\nIn this optional notebook, you will use [Google Search](https://google.com/) results with the Gemini API in a technique called grounding, where the model is connected to verifiable sources of information. Using search grounding is similar to using the RAG system you implemented earlier in the week, but the Gemini API automates a lot of it for you. The model generates Google Search queries and invokes the searches automatically, retrieving relevant data from Google's index of the web and providing links to search suggestions that support the query, so your users can verify the sources.\n\n## Enable billing or use AI Studio\n\n**Important!**\n\nThere are two ways to complete this codelab. Either through Google AI Studio, or through the API.\n\nGrounding with Google Search is only available through the API for **\"pay-as-you-go\"** accounts. However, you can try the feature for **no charge** in [Google AI Studio](https://aistudio.google.com/). **You are not required to enable billing to complete this course.**\n\nContinue on with this guide from the `API: Get set up` section if you have enabled billing for your API key, or continue to `No charge: Use Google AI Studio` to try out the feature free of charge.\n\nNote that Grounding with Google Search has been released as a limited launch and is not available in all locations. The EEA, UK, and CH regions will be supported at a later date. Running this notebook is **optional** and not required for the 5-day GenAI course.\n\nCheck out the following links related to billing:\n\n* Learn how to [enable billing](https://ai.google.dev/gemini-api/docs/billing#enable-cloud-billing)\n* Learn about Google Cloud's [$300 credit for new customers](https://cloud.google.com/free/docs/free-cloud-features) and [other no-cost options](https://cloud.google.com/free)\n* View the [pricing page](https://ai.google.dev/pricing)","metadata":{"id":"q-mcOl0JY8Xg"}},{"cell_type":"markdown","source":"## No charge: Use Google AI Studio\n\nIf you wish to try out grounding with Google Search without enabling billing, you can use AI Studio. There are `Open in AI Studio` links in this codelab, or you can follow this short section to learn how to enable and use the feature for your own queries.\n\n### Open AI Studio\n\nStart by going to [AI Studio](https://aistudio.google.com/prompts/new_chat). You should be in the \"New chat\" interface.\n\nSearch Grounding requires a **002** model, so be sure to select one, such as `Gemini Flash 002`.\n\n![New chat in AI Studio](https://storage.googleapis.com/generativeai-downloads/kaggle/ais-newchat.png)\n\n### Ask a question\n\nNow enter a prompt into the chat interface. Try asking something that is timely and might require recent information to answer, like a recent sport score. For this query, grounding will be **disabled** by default.\n\nThis screenshow shows the response for `What were the top halloween costumes this year?`. Every execution will be different but typically the model talks about 2023, and hedges its responses saying it doesn't have access to specific information resulting in a general comment, rather than specific answers.\n\n![Sample question-answer pair without grounding](https://storage.googleapis.com/generativeai-downloads/kaggle/halloween-ungrounded.png)\n\n### Enable grounding\n\nOn the right-hand sidebar, under the `Tools` section. Find and enable the `Grounding` option.\n\n![Enable grounding button](https://storage.googleapis.com/generativeai-downloads/kaggle/enable-grounding.png)\n\nNow re-run your question by hovering over the Use prompt in the chat history, and pressing the `Edit` button that appears in the upper corner.\n\n![Edit prompt button](https://storage.googleapis.com/generativeai-downloads/kaggle/edit-button.png)\n\nThe `Edit` button will turn into the Gemini âœ¨ icon that you can press to re-run your prompt.\n\n![Re-run prompt button](https://storage.googleapis.com/generativeai-downloads/kaggle/re-run-button.png)\n\nYou should now see a response generated that references sources from Google Search.\n\n![Response with grounded sources from Google!](https://storage.googleapis.com/generativeai-downloads/kaggle/halloween-grounded.png)\n\nFor an explanation of `Dynamic retrieval` you can see the `Dynamic grounding` section at the end of this notebook.\n\n\n### Try your own queries\n\nExplore this interface and try some other queries. Share what works well in the [Discord](https://discord.com/channels/1101210829807956100/1303438361117069363)! You can start from [this blank template](https://aistudio.google.com/app/prompts/1FZtxKLFZIJ1p_0rICu8K2CNIF1tkAnf4) that has search grounding enabled.\n\nThe remaining steps require an API key with billing enabled. They are not required to complete this course; if you have tried grounding in AI Studio you are done for this notebook.","metadata":{}},{"cell_type":"markdown","source":"## API: Get set up\n\nThis section requires an API key with billing enabled. Start by installing and importing the Gemini API Python SDK.","metadata":{"id":"Qcyq976Gbwpo"}},{"cell_type":"code","source":"%pip install -q -U 'google-generativeai>=0.8.3'","metadata":{"id":"1ZLC4ORSbqme","execution":{"iopub.status.busy":"2024-11-14T18:18:04.106632Z","iopub.execute_input":"2024-11-14T18:18:04.107012Z","iopub.status.idle":"2024-11-14T18:18:28.351413Z","shell.execute_reply.started":"2024-11-14T18:18:04.106974Z","shell.execute_reply":"2024-11-14T18:18:28.350136Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You do not need to restart the kernel.","metadata":{}},{"cell_type":"code","source":"import google.generativeai as genai\nfrom IPython.display import Markdown, HTML, display","metadata":{"id":"FNkHtOAmbt2B","execution":{"iopub.status.busy":"2024-11-14T18:18:47.840518Z","iopub.execute_input":"2024-11-14T18:18:47.841625Z","iopub.status.idle":"2024-11-14T18:18:48.935157Z","shell.execute_reply.started":"2024-11-14T18:18:47.841567Z","shell.execute_reply":"2024-11-14T18:18:48.934082Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Set up your API key\n\nTo run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n\nIf you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n\nTo make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook.","metadata":{"id":"_NO9cdffb4KR"}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"id":"8NAmACYHb5DK","execution":{"iopub.status.busy":"2024-11-14T18:18:53.233435Z","iopub.execute_input":"2024-11-14T18:18:53.234223Z","iopub.status.idle":"2024-11-14T18:18:53.709743Z","shell.execute_reply.started":"2024-11-14T18:18:53.234179Z","shell.execute_reply":"2024-11-14T18:18:53.708600Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n\n![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)","metadata":{"id":"cfb5d41c4a03"}},{"cell_type":"markdown","source":"### Explore available models\n\nSearch grounding is a tool available in the `-002` series of models. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. You can also find more information about different model capabilities on [the models page](https://ai.google.dev/gemini-api/docs/models/gemini).","metadata":{"id":"Rvre6fOrcHi2"}},{"cell_type":"code","source":"for model in genai.list_models():\n    if \"002\" in model.name:\n        print(model.name)","metadata":{"id":"p6G2H6N4dT02","execution":{"iopub.status.busy":"2024-11-14T18:19:01.145781Z","iopub.execute_input":"2024-11-14T18:19:01.146610Z","iopub.status.idle":"2024-11-14T18:19:02.015481Z","shell.execute_reply.started":"2024-11-14T18:19:01.146520Z","shell.execute_reply":"2024-11-14T18:19:02.014369Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"models/gemini-1.5-pro-002\nmodels/gemini-1.5-flash-002\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Use search grounding\n\nTo enable search grounding, you specify it as a tool: `google_search_retrieval`. Like other tools, this can be supplied as a parameter to the model (to use on all chat turns or calls to `generate_content`), or it can be supplied per-turn to `chat.send_message`.\n\n\n<table align=left>\n  <td>\n    <a target=\"_blank\" href=\"https://aistudio.google.com/app/prompts/1GTkO-gH4vd6G7LpBJ6Ay7U1OaJer7yDD\"><img src=\"https://ai.google.dev/site-assets/images/marketing/home/icon-ais.png\" style=\"height: 24px\" height=24/> Open in AI Studio</a>\n  </td>\n</table>","metadata":{"id":"HW5RVNUierrQ"}},{"cell_type":"code","source":"# Ask for information without search grounding.\nmodel = genai.GenerativeModel(\"gemini-1.5-flash-002\")\n\nresponse = model.generate_content(\"When and where is the Los Angeles Clippers next game?\")\n\nMarkdown(response.text)","metadata":{"id":"JZmdaOlVfCgd","execution":{"iopub.status.busy":"2024-11-14T18:19:25.849405Z","iopub.execute_input":"2024-11-14T18:19:25.849818Z","iopub.status.idle":"2024-11-14T18:19:26.671890Z","shell.execute_reply.started":"2024-11-14T18:19:25.849780Z","shell.execute_reply":"2024-11-14T18:19:26.670676Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I do not have access to real-time information, including live sports schedules.  To find the Los Angeles Clippers' next game, I recommend checking a sports website such as ESPN, the NBA website, or the Clippers' official website.\n"},"metadata":{}}]},{"cell_type":"markdown","source":"Now try with grounding enabled.\n\n<table align=left>\n  <td>\n    <a target=\"_blank\" href=\"https://aistudio.google.com/prompts/14lDR0VjSni6BEUCZUBqj5PzTn3J194Th\"><img src=\"https://ai.google.dev/site-assets/images/marketing/home/icon-ais.png\" style=\"height: 24px\" height=24/> Open in AI Studio</a>\n  </td>\n</table>","metadata":{}},{"cell_type":"code","source":"# And now re-run the same query with search grounding enabled.\nmodel = genai.GenerativeModel(\n    \"gemini-1.5-flash-002\",\n    tools=\"google_search_retrieval\")\n\nresponse = model.generate_content(\"When and where is the Los Angeles Clippers next game?\")\nrc = response.candidates[0]\n\nMarkdown(rc.content.parts[0].text)","metadata":{"id":"i7jqG3nww6kU","execution":{"iopub.status.busy":"2024-11-14T18:19:46.536662Z","iopub.execute_input":"2024-11-14T18:19:46.537467Z","iopub.status.idle":"2024-11-14T18:19:47.573238Z","shell.execute_reply.started":"2024-11-14T18:19:46.537427Z","shell.execute_reply":"2024-11-14T18:19:47.571729Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# And now re-run the same query with search grounding enabled.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-flash-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     tools\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle_search_retrieval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhen and where is the Los Angeles Clippers next game?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m rc \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m Markdown(rc\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/generativeai/client.py:267\u001b[0m, in \u001b[0;36m_ClientManager.make_client.<locals>.add_default_metadata_wrapper.<locals>.call\u001b[0;34m(metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;241m*\u001b[39margs, metadata\u001b[38;5;241m=\u001b[39m(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    266\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata)\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n","\u001b[0;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."],"ename":"ResourceExhausted","evalue":"429 Resource has been exhausted (e.g. check quota).","output_type":"error"}]},{"cell_type":"markdown","source":"If you receive a `429 Resource has been exhausted` error, you are likely using a free tier API key. You can choose to enable billing (but this will incur charges), or you can try the queries in Google AI Studio by following the `Open in AI Studio` links above.","metadata":{"id":"SJc_0FFBgoiJ"}},{"cell_type":"markdown","source":"### Response metadata\n\nWhen search grounding is used, the model returns extra metadata that includes links to search suggestions, supporting documents and information on how the supporting documents were used.\n\nEach \"grounding chunk\" represents information retrieved from Google Search that was used in the grounded generation request. Following the URI will take you to the source.","metadata":{"id":"SJc_0FFBgoiJ"}},{"cell_type":"code","source":"chunks = rc.grounding_metadata.grounding_chunks\nfor chunk in chunks:\n    print(chunk)","metadata":{"id":"2P7IYMcvxtcy","execution":{"iopub.status.busy":"2024-11-14T03:14:18.227894Z","iopub.execute_input":"2024-11-14T03:14:18.228318Z","iopub.status.idle":"2024-11-14T03:14:18.234551Z","shell.execute_reply.started":"2024-11-14T03:14:18.22828Z","shell.execute_reply":"2024-11-14T03:14:18.23339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As part of the response, there is a standalone styled HTML content block that you use to link back to relevant search suggestions related to the generation.","metadata":{"id":"ziYb2Fkjzwwx"}},{"cell_type":"code","source":"HTML(rc.grounding_metadata.search_entry_point.rendered_content)","metadata":{"id":"DQAgIGJmfxqC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `grounding_supports` in the metadata provide a way for you to correlate the grounding chunks used to the generated output text.","metadata":{"id":"pJpqJopp0H0M"}},{"cell_type":"code","source":"supports = rc.grounding_metadata.grounding_supports\nfor support in supports:\n    print(support)","metadata":{"id":"sHg9Yq9U0r89","execution":{"iopub.status.busy":"2024-11-14T03:14:32.277099Z","iopub.execute_input":"2024-11-14T03:14:32.277505Z","iopub.status.idle":"2024-11-14T03:14:32.283343Z","shell.execute_reply.started":"2024-11-14T03:14:32.277465Z","shell.execute_reply":"2024-11-14T03:14:32.28224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These supports can be used to highlight text in the response, or build tables of footnotes.","metadata":{"id":"wkQAGyi87FGn"}},{"cell_type":"code","source":"import io\n\nmarkdown_buffer = io.StringIO()\n\n# Print the text with footnote markers.\nmarkdown_buffer.write(\"Supported text:\\n\\n\")\nfor support in supports:\n    markdown_buffer.write(\" * \")\n    markdown_buffer.write(\n        response.text[support.segment.start_index : support.segment.end_index]\n    )\n\n    for i in support.grounding_chunk_indices:\n        chunk = chunks[i].web\n        markdown_buffer.write(f\"<sup>[{i+1}]</sup>\")\n\n    markdown_buffer.write(\"\\n\\n\")\n\n\n# And print the footnotes.\nmarkdown_buffer.write(\"Citations:\\n\\n\")\nfor i, chunk in enumerate(chunks, start=1):\n    markdown_buffer.write(f\"* {i}: [{chunk.web.title}]({chunk.web.uri})\\n\")\n\n\nMarkdown(markdown_buffer.getvalue())","metadata":{"id":"9_dEINt43C62","execution":{"iopub.status.busy":"2024-11-14T03:14:35.21884Z","iopub.execute_input":"2024-11-14T03:14:35.219234Z","iopub.status.idle":"2024-11-14T03:14:35.22931Z","shell.execute_reply.started":"2024-11-14T03:14:35.219195Z","shell.execute_reply":"2024-11-14T03:14:35.228309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dynamic grounding\n\nIn a context where you may not know in advance whether to enable search grounding or not, you can provide the model with a threshold over which it will use search grounding. This is helpful in conversational contexts, where not every turn of conversation requires search data to support a response.\n\nIf you know whether to enable Search for any given chat turn, you can provide the tool explicitly.\n\n\n<table align=left>\n  <td>\n    <a target=\"_blank\" href=\"https://aistudio.google.com/prompts/1VBx_R16kNWa8g7lpLxQPx_08sFtd7tcd\"><img src=\"https://ai.google.dev/site-assets/images/marketing/home/icon-ais.png\" style=\"height: 24px\" height=24/> Open in AI Studio</a>\n  </td>\n</table>","metadata":{"id":"suX0M2By8LIN"}},{"cell_type":"code","source":"nosearch_model = genai.GenerativeModel(\"gemini-1.5-flash-002\")\nchat = nosearch_model.start_chat()\n\n# No search grounding.\nr = chat.send_message(\"Hello friendly chatbot!\")\n\n# Enable search for just this turn.\nr = chat.send_message(\n    \"Who took home the 2023 cricket world cup?\", tools=\"google_search_retrieval\"\n)\n\nMarkdown(r.text)","metadata":{"id":"6FLf92417p_4","execution":{"iopub.status.busy":"2024-11-14T03:14:40.532771Z","iopub.execute_input":"2024-11-14T03:14:40.53326Z","iopub.status.idle":"2024-11-14T03:14:42.795841Z","shell.execute_reply.started":"2024-11-14T03:14:40.533214Z","shell.execute_reply":"2024-11-14T03:14:42.794674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HTML(r.candidates[0].grounding_metadata.search_entry_point.rendered_content)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Or you can let the Gemini API calculate a likelihood that the response needs search backing, and define the threshold to use.","metadata":{"id":"6nSCaNfL9wSL"}},{"cell_type":"code","source":"# The dynamic retrieval score is a probability, so the threshold\n# must also be bound by [0, 1].\nsearch_config = {\n    \"dynamic_retrieval_config\": {\"mode\": \"MODE_DYNAMIC\", \"dynamic_threshold\": 0.5}\n}\n\nmaybe_search_model = genai.GenerativeModel(\n    \"gemini-1.5-flash-002\", tools={\"google_search_retrieval\": search_config}\n)\n\nchat = maybe_search_model.start_chat()\n\nr = chat.send_message(\"Hello friendly chatbot!\")\nrc = r.candidates[0]\nscore = rc.grounding_metadata.retrieval_metadata.google_search_dynamic_retrieval_score\nprint(f\"First turn: {score=}\")\n\nr = chat.send_message(\"Who took home the 2023 cricket world cup?\")\nrc = r.candidates[0]\nscore = rc.grounding_metadata.retrieval_metadata.google_search_dynamic_retrieval_score\nprint(f\"Second turn: {score=}\")\nprint()\n\ndisplay(Markdown(r.text))","metadata":{"id":"WdqdYOND98M4","execution":{"iopub.status.busy":"2024-11-14T03:16:28.248699Z","iopub.execute_input":"2024-11-14T03:16:28.249083Z","iopub.status.idle":"2024-11-14T03:16:30.218809Z","shell.execute_reply.started":"2024-11-14T03:16:28.249047Z","shell.execute_reply":"2024-11-14T03:16:30.217776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HTML(rc.grounding_metadata.search_entry_point.rendered_content)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Further reading\n\nWhen using search grounding, there are some specific requirements that you must follow, including when and how to show search suggestions, and how to use the grounding links.  Be sure to read and follow the details in the [search grounding capability guide](https://ai.google.dev/gemini-api/docs/grounding) and the [search suggestions guide](https://ai.google.dev/gemini-api/docs/grounding/search-suggestions).","metadata":{"id":"Cp7gvdM-zOf0"}}]}